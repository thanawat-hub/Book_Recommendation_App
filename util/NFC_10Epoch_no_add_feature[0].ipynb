{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-6A9MUZzjy2a"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "https://www.kaggle.com/code/ahb1104/neural-collaborative-filtering"
      ],
      "metadata": {
        "id": "kvWt8ffKyU9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get dataset from goolge drive"
      ],
      "metadata": {
        "id": "cjjrLWGp8CBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNs8ah--fxdw",
        "outputId": "e9fce911-72c9-42ba-ed83-500359bebcd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/1_try_/RS_book\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWGQ_8ajf5c-",
        "outputId": "11901f90-863e-4c18-cb44-3845e0b3c01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Book Recommendation Dataset.zip'   DeepRec.png     recsys_taxonomy2.png\n",
            " Books.csv\t\t\t    pytorch.ipynb   Untitled0.ipynb\n",
            " classicRec.png\t\t\t    Ratings.csv     Users.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q \"Book Recommendation Dataset.zip\"\n",
        "# !ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcMbjVtHgOdS",
        "outputId": "3e523c9a-4151-48e0-f109-624234af474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Books.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: 'Book Recommendation Dataset.zip'   DeepRec.png     recsys_taxonomy2.png\n",
            " Books.csv\t\t\t    pytorch.ipynb   Untitled0.ipynb\n",
            " classicRec.png\t\t\t    Ratings.csv     Users.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/1_try_/RS_book/Books.csv /content/\n",
        "!cp /content/drive/MyDrive/1_try_/RS_book/Ratings.csv /content/\n",
        "!cp /content/drive/MyDrive/1_try_/RS_book/Users.csv /content/"
      ],
      "metadata": {
        "id": "OCU7d5vkf1Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## kaggle"
      ],
      "metadata": {
        "id": "MYM9kf7-8F2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "books=pd.read_csv(\"/content/Books.csv\",low_memory=False)\n",
        "ratings=pd.read_csv(\"/content/Ratings.csv\",low_memory=False)\n",
        "users=pd.read_csv(\"/content//Users.csv\",low_memory=False)"
      ],
      "metadata": {
        "id": "lUmvdAqbWrVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EERiYOeGW_RZ",
        "outputId": "779603be-a6bf-4657-845c-f6f521cc59dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "User-ID        0\n",
              "ISBN           0\n",
              "Book-Rating    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4sIviaYXAdq",
        "outputId": "50edd6a9-a0fd-4483-fc55-f9793584c8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "User-ID          0\n",
              "Location         0\n",
              "Age         110762\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M-9HUxFXByf",
        "outputId": "13d882f9-f149-4212-cb44-d14b072bacd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ISBN                   0\n",
              "Book-Title             0\n",
              "Book-Author            2\n",
              "Year-Of-Publication    0\n",
              "Publisher              2\n",
              "Image-URL-S            0\n",
              "Image-URL-M            0\n",
              "Image-URL-L            3\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sQhwxykWvKp",
        "outputId": "1f1fe5ce-d679-4147-adef-854e154cc116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1149780"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_df=pd.read_csv(\"/content/Books.csv\",low_memory=False)\n",
        "ratings_df=pd.read_csv(\"/content/Ratings.csv\",low_memory=False)\n",
        "users_df=pd.read_csv(\"/content/Users.csv\",low_memory=False)"
      ],
      "metadata": {
        "id": "QxdWlCM5ctHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LabelEncoder"
      ],
      "metadata": {
        "id": "4DJJJdnGXFKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoders for user and item IDs\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform user and item IDs\n",
        "ratings['user_id'] = user_encoder.fit_transform(ratings['User-ID'])\n",
        "ratings['item_id'] = item_encoder.fit_transform(ratings['ISBN'])\n",
        "\n",
        "# Fit and transform user and item IDs\n",
        "ratings_df['user_id'] = user_encoder.fit_transform(ratings_df['User-ID'])\n",
        "ratings_df['item_id'] = item_encoder.fit_transform(ratings_df['ISBN'])"
      ],
      "metadata": {
        "id": "nc6bYVvkXEgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qk8G3fuMb69q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_train = ratings[0:919824]\n",
        "ratings_test = ratings[919825:].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fKz4LxQ2YU_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "id": "3hzp23moYR8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'user_id': self.data['user_id'][idx],\n",
        "            'book_id': self.data['item_id'][idx],\n",
        "            'rating': self.data['Book-Rating'][idx]\n",
        "        }"
      ],
      "metadata": {
        "id": "dI-ej8tlYSdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Instantiate train and test datasets\n",
        "train_dataset = RatingDataset(ratings_train)\n",
        "test_dataset = RatingDataset(ratings_test)\n",
        "\n",
        "# Create train and test loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Nw06JNY8h2HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-taGFr9NiAPm",
        "outputId": "328815de-307d-460c-d5b2-fcc52df4eabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "919824\n",
            "14373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GMF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size):\n",
        "        super(GMF, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
        "        self.fc = nn.Linear(embedding_size, 32)\n",
        "        self.output_layer = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        user_embed = self.user_embedding(user_ids)\n",
        "        item_embed = self.item_embedding(item_ids)\n",
        "        element_product = user_embed * item_embed\n",
        "        x = self.fc(element_product)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        output = self.output_layer(x)\n",
        "        output = torch.sigmoid(output)  # Ensure output is between 0 and 1\n",
        "        return output.view(-1)"
      ],
      "metadata": {
        "id": "Ilj6Ajk3iAeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size, hidden_layers=[64, 32]):\n",
        "        super(MLP, self).__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
        "        layers = []\n",
        "        input_size = embedding_size * 2\n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.append(nn.Linear(input_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_size = hidden_size\n",
        "        layers.append(nn.Linear(hidden_layers[-1], 1))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        user_embed = self.user_embedding(user_ids)\n",
        "        item_embed = self.item_embedding(item_ids)\n",
        "        concat_embed = torch.cat((user_embed, item_embed), dim=1)\n",
        "        output = self.layers(concat_embed)\n",
        "        output = torch.sigmoid(output)  # Ensure output is between 0 and 1\n",
        "        return output.view(-1)"
      ],
      "metadata": {
        "id": "ctFy4d_siM7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NCF(nn.Module):\n",
        "    def __init__(self, gmf_model, mlp_model):\n",
        "        super(NCF, self).__init__()\n",
        "        self.gmf = gmf_model\n",
        "        self.mlp = mlp_model\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        gmf_output = self.gmf(user_ids, item_ids)\n",
        "        mlp_output = self.mlp(user_ids, item_ids)\n",
        "        combined_output = (gmf_output + mlp_output) / 2\n",
        "        return combined_output"
      ],
      "metadata": {
        "id": "GJw3GTtaiOHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(ratings['User-ID'].unique())\n",
        "num_items = len(ratings['ISBN'].unique())\n",
        "embedding_size = 64\n",
        "hidden_layers = [128, 64, 32]"
      ],
      "metadata": {
        "id": "AM2OuWXSiPhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF_4LcnGieRT",
        "outputId": "10316023-6229-41d3-c992-cd60c18dc16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GMF model\n",
        "gmf_model = GMF(num_users, num_items, embedding_size).to(device)\n",
        "\n",
        "# Initialize MLP model\n",
        "mlp_model = MLP(num_users, num_items, embedding_size, hidden_layers).to(device)"
      ],
      "metadata": {
        "id": "571kvHZ_iRBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss criterion for GMF and MLP models\n",
        "models_criterion = nn.MSELoss()\n",
        "\n",
        "# Optimizer for GMF model\n",
        "gmf_optimizer = optim.Adam(gmf_model.parameters(), lr=0.001)\n",
        "\n",
        "# Optimizer for MLP model\n",
        "mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "2i_ybIlVielZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gmf(model, dataloader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        i=0\n",
        "        total_diff=0\n",
        "        total_len=0\n",
        "        for batch in dataloader:\n",
        "            user_ids = batch['user_id'].to(device)\n",
        "            item_ids = batch['book_id'].to(device)\n",
        "            ratings = batch['rating'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(user_ids, item_ids)\n",
        "            loss = criterion(predictions, (ratings.float()/10) )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i % 1000 == 0):\n",
        "                actual_ratings = 10*predictions\n",
        "                diff = torch.abs( actual_ratings - ratings ).sum().item()\n",
        "                print(f'Batch [{i+1}/{len(dataloader)}], Loss: {loss.item()}, Avg. Diff: { (diff/len(ratings)) }')\n",
        "\n",
        "            i = i + 1\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'GMF Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader)}')"
      ],
      "metadata": {
        "id": "KjJ6pG_DijQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp(model, dataloader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        i=0\n",
        "        for batch in dataloader:\n",
        "            user_ids = batch['user_id'].to(device)\n",
        "            item_ids = batch['book_id'].to(device)\n",
        "            ratings = batch['rating'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(user_ids, item_ids)\n",
        "            loss = criterion(predictions, (ratings.float()/10))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i % 1000 == 0):\n",
        "                actual_ratings = 10*predictions\n",
        "                diff = torch.abs( actual_ratings - ratings ).sum().item()\n",
        "                print(f'Batch [{i+1}/{len(dataloader)}], Loss: {loss.item()}, Avg. Diff: { (diff/len(ratings)) }')\n",
        "\n",
        "            i = i + 1\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'MLP Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader)}')"
      ],
      "metadata": {
        "id": "zA7Tbc6milgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "print(\"Training GMF...\")\n",
        "train_gmf(gmf_model, train_loader, models_criterion, gmf_optimizer, num_epochs)\n",
        "\n",
        "print(\"Training MLP...\")\n",
        "train_mlp(mlp_model, train_loader, models_criterion, mlp_optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL_39RPRinf9",
        "outputId": "002a4aa4-749d-471f-8675-1fa699af61e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMF...\n",
            "Batch [1/14373], Loss: 0.20831328630447388, Avg. Diff: 4.33951473236084\n",
            "Batch [1001/14373], Loss: 0.15833786129951477, Avg. Diff: 3.644221305847168\n",
            "Batch [2001/14373], Loss: 0.14095795154571533, Avg. Diff: 3.542548418045044\n",
            "Batch [3001/14373], Loss: 0.15562985837459564, Avg. Diff: 3.6924285888671875\n",
            "Batch [4001/14373], Loss: 0.12557071447372437, Avg. Diff: 3.2700376510620117\n",
            "Batch [5001/14373], Loss: 0.11599335074424744, Avg. Diff: 3.1836767196655273\n",
            "Batch [6001/14373], Loss: 0.15885818004608154, Avg. Diff: 3.6407132148742676\n",
            "Batch [7001/14373], Loss: 0.13180813193321228, Avg. Diff: 3.2872154712677\n",
            "Batch [8001/14373], Loss: 0.12217004597187042, Avg. Diff: 3.235283374786377\n",
            "Batch [9001/14373], Loss: 0.1398754119873047, Avg. Diff: 3.2527527809143066\n",
            "Batch [10001/14373], Loss: 0.12118864059448242, Avg. Diff: 3.0927233695983887\n",
            "Batch [11001/14373], Loss: 0.17020156979560852, Avg. Diff: 3.7254559993743896\n",
            "Batch [12001/14373], Loss: 0.15016885101795197, Avg. Diff: 3.387502908706665\n",
            "Batch [13001/14373], Loss: 0.15782110393047333, Avg. Diff: 3.4621641635894775\n",
            "Batch [14001/14373], Loss: 0.12932942807674408, Avg. Diff: 3.1970789432525635\n",
            "GMF Epoch [1/3], Loss: 0.1412144377112289\n",
            "Batch [1/14373], Loss: 0.1367064267396927, Avg. Diff: 3.263489246368408\n",
            "Batch [1001/14373], Loss: 0.16465742886066437, Avg. Diff: 3.4245858192443848\n",
            "Batch [2001/14373], Loss: 0.12466654181480408, Avg. Diff: 2.996246099472046\n",
            "Batch [3001/14373], Loss: 0.12049008905887604, Avg. Diff: 2.9931650161743164\n",
            "Batch [4001/14373], Loss: 0.11529126018285751, Avg. Diff: 2.916374921798706\n",
            "Batch [5001/14373], Loss: 0.12606850266456604, Avg. Diff: 2.9818620681762695\n",
            "Batch [6001/14373], Loss: 0.12783481180667877, Avg. Diff: 3.020620346069336\n",
            "Batch [7001/14373], Loss: 0.10880055278539658, Avg. Diff: 2.545973300933838\n",
            "Batch [8001/14373], Loss: 0.09372656047344208, Avg. Diff: 2.380504608154297\n",
            "Batch [9001/14373], Loss: 0.11480026692152023, Avg. Diff: 2.8191919326782227\n",
            "Batch [10001/14373], Loss: 0.14209289848804474, Avg. Diff: 3.1344149112701416\n",
            "Batch [11001/14373], Loss: 0.11738753318786621, Avg. Diff: 2.804835319519043\n",
            "Batch [12001/14373], Loss: 0.14663420617580414, Avg. Diff: 3.3492088317871094\n",
            "Batch [13001/14373], Loss: 0.112153559923172, Avg. Diff: 2.7316787242889404\n",
            "Batch [14001/14373], Loss: 0.12289829552173615, Avg. Diff: 2.992586135864258\n",
            "GMF Epoch [2/3], Loss: 0.12141483508432482\n",
            "Batch [1/14373], Loss: 0.12781065702438354, Avg. Diff: 2.8667678833007812\n",
            "Batch [1001/14373], Loss: 0.12236069142818451, Avg. Diff: 2.762104034423828\n",
            "Batch [2001/14373], Loss: 0.08625556528568268, Avg. Diff: 2.2992122173309326\n",
            "Batch [3001/14373], Loss: 0.10493969917297363, Avg. Diff: 2.5458121299743652\n",
            "Batch [4001/14373], Loss: 0.10211181640625, Avg. Diff: 2.4399678707122803\n",
            "Batch [5001/14373], Loss: 0.11646152287721634, Avg. Diff: 2.70800518989563\n",
            "Batch [6001/14373], Loss: 0.08724778890609741, Avg. Diff: 2.310479164123535\n",
            "Batch [7001/14373], Loss: 0.10750263184309006, Avg. Diff: 2.4388632774353027\n",
            "Batch [8001/14373], Loss: 0.10528244078159332, Avg. Diff: 2.5981762409210205\n",
            "Batch [9001/14373], Loss: 0.08018641918897629, Avg. Diff: 2.1647391319274902\n",
            "Batch [10001/14373], Loss: 0.11791029572486877, Avg. Diff: 2.744368553161621\n",
            "Batch [11001/14373], Loss: 0.10939083993434906, Avg. Diff: 2.6152358055114746\n",
            "Batch [12001/14373], Loss: 0.10471217334270477, Avg. Diff: 2.6294338703155518\n",
            "Batch [13001/14373], Loss: 0.12796419858932495, Avg. Diff: 2.8195252418518066\n",
            "Batch [14001/14373], Loss: 0.07874928414821625, Avg. Diff: 2.1507248878479004\n",
            "GMF Epoch [3/3], Loss: 0.10638235946876813\n",
            "Training MLP...\n",
            "Batch [1/14373], Loss: 0.20079682767391205, Avg. Diff: 4.245512008666992\n",
            "Batch [1001/14373], Loss: 0.10993826389312744, Avg. Diff: 2.993104934692383\n",
            "Batch [2001/14373], Loss: 0.15524780750274658, Avg. Diff: 3.5357494354248047\n",
            "Batch [3001/14373], Loss: 0.14172129333019257, Avg. Diff: 3.261618137359619\n",
            "Batch [4001/14373], Loss: 0.09759479761123657, Avg. Diff: 2.650618314743042\n",
            "Batch [5001/14373], Loss: 0.12691104412078857, Avg. Diff: 2.903541088104248\n",
            "Batch [6001/14373], Loss: 0.0977979302406311, Avg. Diff: 2.5480573177337646\n",
            "Batch [7001/14373], Loss: 0.106551393866539, Avg. Diff: 2.6240410804748535\n",
            "Batch [8001/14373], Loss: 0.11005572974681854, Avg. Diff: 2.66384220123291\n",
            "Batch [9001/14373], Loss: 0.13823211193084717, Avg. Diff: 3.0832016468048096\n",
            "Batch [10001/14373], Loss: 0.1343608796596527, Avg. Diff: 3.012634515762329\n",
            "Batch [11001/14373], Loss: 0.12577128410339355, Avg. Diff: 3.0428571701049805\n",
            "Batch [12001/14373], Loss: 0.111996129155159, Avg. Diff: 2.7005481719970703\n",
            "Batch [13001/14373], Loss: 0.1354968100786209, Avg. Diff: 3.239612579345703\n",
            "Batch [14001/14373], Loss: 0.11546824127435684, Avg. Diff: 2.8061418533325195\n",
            "MLP Epoch [1/3], Loss: 0.12466803465342045\n",
            "Batch [1/14373], Loss: 0.1222531795501709, Avg. Diff: 2.9999947547912598\n",
            "Batch [1001/14373], Loss: 0.1169847846031189, Avg. Diff: 2.749295473098755\n",
            "Batch [2001/14373], Loss: 0.11006613075733185, Avg. Diff: 2.496408224105835\n",
            "Batch [3001/14373], Loss: 0.12230103462934494, Avg. Diff: 2.854227066040039\n",
            "Batch [4001/14373], Loss: 0.10934567451477051, Avg. Diff: 2.6066932678222656\n",
            "Batch [5001/14373], Loss: 0.12394669651985168, Avg. Diff: 2.8245043754577637\n",
            "Batch [6001/14373], Loss: 0.1168285682797432, Avg. Diff: 2.750391960144043\n",
            "Batch [7001/14373], Loss: 0.11610575020313263, Avg. Diff: 2.9199142456054688\n",
            "Batch [8001/14373], Loss: 0.12170445173978806, Avg. Diff: 2.897402048110962\n",
            "Batch [9001/14373], Loss: 0.11765900254249573, Avg. Diff: 2.836103916168213\n",
            "Batch [10001/14373], Loss: 0.08771831542253494, Avg. Diff: 2.234729766845703\n",
            "Batch [11001/14373], Loss: 0.09190411865711212, Avg. Diff: 2.384725570678711\n",
            "Batch [12001/14373], Loss: 0.1051168367266655, Avg. Diff: 2.6579229831695557\n",
            "Batch [13001/14373], Loss: 0.11586292833089828, Avg. Diff: 2.755122661590576\n",
            "Batch [14001/14373], Loss: 0.10707246512174606, Avg. Diff: 2.3352854251861572\n",
            "MLP Epoch [2/3], Loss: 0.11273223445506814\n",
            "Batch [1/14373], Loss: 0.09083156287670135, Avg. Diff: 2.1052448749542236\n",
            "Batch [1001/14373], Loss: 0.08123165369033813, Avg. Diff: 2.3711957931518555\n",
            "Batch [2001/14373], Loss: 0.09683887660503387, Avg. Diff: 2.411332607269287\n",
            "Batch [3001/14373], Loss: 0.07557301968336105, Avg. Diff: 2.2213563919067383\n",
            "Batch [4001/14373], Loss: 0.0977080762386322, Avg. Diff: 2.47068452835083\n",
            "Batch [5001/14373], Loss: 0.08006729185581207, Avg. Diff: 2.088400363922119\n",
            "Batch [6001/14373], Loss: 0.1069796085357666, Avg. Diff: 2.624342679977417\n",
            "Batch [7001/14373], Loss: 0.110603928565979, Avg. Diff: 2.811249256134033\n",
            "Batch [8001/14373], Loss: 0.0858212262392044, Avg. Diff: 2.1209824085235596\n",
            "Batch [9001/14373], Loss: 0.07255291193723679, Avg. Diff: 2.178372621536255\n",
            "Batch [10001/14373], Loss: 0.12668251991271973, Avg. Diff: 2.8898730278015137\n",
            "Batch [11001/14373], Loss: 0.09108859300613403, Avg. Diff: 2.2914257049560547\n",
            "Batch [12001/14373], Loss: 0.07896661758422852, Avg. Diff: 2.15409517288208\n",
            "Batch [13001/14373], Loss: 0.07467702776193619, Avg. Diff: 2.0441484451293945\n",
            "Batch [14001/14373], Loss: 0.08665896207094193, Avg. Diff: 2.1685280799865723\n",
            "MLP Epoch [3/3], Loss: 0.10653474366949785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NCF(gmf_model, mlp_model)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "rOvlJE4-ipTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    i=0\n",
        "    for batch in train_loader:\n",
        "        user_ids = batch['user_id'].to(device)\n",
        "        item_ids = batch['book_id'].to(device)\n",
        "        ratings = batch['rating'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(user_ids, item_ids)\n",
        "        loss = criterion(predictions, (ratings.float()/10))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i % 1000 == 0):\n",
        "            actual_ratings = 10*predictions\n",
        "            rmse = math.sqrt(torch.square(actual_ratings-ratings).sum().item()/len(ratings))\n",
        "            diff = torch.abs( actual_ratings - ratings ).sum().item()\n",
        "            print(f'Batch [{i+1}/{len(train_loader)}], Loss: {loss.item()}, Avg. Diff: { (diff/len(ratings)) }, RMSE: {rmse}')\n",
        "\n",
        "\n",
        "        i = i + 1\n",
        "\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Z_9PfzjICe",
        "outputId": "a95e6659-6c6e-4b3f-e7ab-4dd3f565aa16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch [1/14373], Loss: 0.08808785676956177, Avg. Diff: 2.330751895904541, RMSE: 2.9679599714638867\n",
            "Batch [1001/14373], Loss: 0.08022172749042511, Avg. Diff: 2.174924850463867, RMSE: 2.8323440694690407\n",
            "Batch [2001/14373], Loss: 0.08313924074172974, Avg. Diff: 2.083922863006592, RMSE: 2.8833873971563513\n",
            "Batch [3001/14373], Loss: 0.08672169595956802, Avg. Diff: 2.1996989250183105, RMSE: 2.944854619788463\n",
            "Batch [4001/14373], Loss: 0.09062895178794861, Avg. Diff: 2.3576345443725586, RMSE: 3.010464220210397\n",
            "Batch [5001/14373], Loss: 0.08294878154993057, Avg. Diff: 2.181122303009033, RMSE: 2.8800829859539543\n",
            "Batch [6001/14373], Loss: 0.08068054914474487, Avg. Diff: 2.1832830905914307, RMSE: 2.840432212339007\n",
            "Batch [7001/14373], Loss: 0.09116290509700775, Avg. Diff: 2.240917205810547, RMSE: 3.0193194750586203\n",
            "Batch [8001/14373], Loss: 0.10987173765897751, Avg. Diff: 2.4459385871887207, RMSE: 3.3146904954225116\n",
            "Batch [9001/14373], Loss: 0.06323565542697906, Avg. Diff: 1.8837368488311768, RMSE: 2.514669959707656\n",
            "Batch [10001/14373], Loss: 0.09222082793712616, Avg. Diff: 2.2568607330322266, RMSE: 3.036788285629382\n",
            "Batch [11001/14373], Loss: 0.0789303183555603, Avg. Diff: 2.161834716796875, RMSE: 2.8094540526541114\n",
            "Batch [12001/14373], Loss: 0.08352596312761307, Avg. Diff: 2.1073198318481445, RMSE: 2.890085860828184\n",
            "Batch [13001/14373], Loss: 0.0824987143278122, Avg. Diff: 2.0159125328063965, RMSE: 2.872259077388668\n",
            "Batch [14001/14373], Loss: 0.1103602796792984, Avg. Diff: 2.5381784439086914, RMSE: 3.3220517618371326\n",
            "Epoch [1/10], Loss: 0.05692780017852783\n",
            "Batch [1/14373], Loss: 0.07174819707870483, Avg. Diff: 1.8930155038833618, RMSE: 2.6785854375563725\n",
            "Batch [1001/14373], Loss: 0.06706243753433228, Avg. Diff: 1.9205423593521118, RMSE: 2.58964148834882\n",
            "Batch [2001/14373], Loss: 0.05441509187221527, Avg. Diff: 1.5506908893585205, RMSE: 2.3327043798268416\n",
            "Batch [3001/14373], Loss: 0.04275445640087128, Avg. Diff: 1.4876751899719238, RMSE: 2.0677149185601085\n",
            "Batch [4001/14373], Loss: 0.09394729882478714, Avg. Diff: 2.336449146270752, RMSE: 3.0650823176968367\n",
            "Batch [5001/14373], Loss: 0.07352481782436371, Avg. Diff: 1.8654924631118774, RMSE: 2.711546024326531\n",
            "Batch [6001/14373], Loss: 0.08466111868619919, Avg. Diff: 2.0013277530670166, RMSE: 2.909658422708896\n",
            "Batch [7001/14373], Loss: 0.06841210275888443, Avg. Diff: 1.9485615491867065, RMSE: 2.615570662103827\n",
            "Batch [8001/14373], Loss: 0.07730142772197723, Avg. Diff: 2.028167724609375, RMSE: 2.7803133984110118\n",
            "Batch [9001/14373], Loss: 0.10537978261709213, Avg. Diff: 2.27978515625, RMSE: 3.2462250720841785\n",
            "Batch [10001/14373], Loss: 0.07911733537912369, Avg. Diff: 1.8585306406021118, RMSE: 2.812780408656057\n",
            "Batch [11001/14373], Loss: 0.055571671575307846, Avg. Diff: 1.5677719116210938, RMSE: 2.357364328309372\n",
            "Batch [12001/14373], Loss: 0.07181382924318314, Avg. Diff: 1.9280884265899658, RMSE: 2.67981019031151\n",
            "Batch [13001/14373], Loss: 0.07668478786945343, Avg. Diff: 1.8800337314605713, RMSE: 2.7692017782967926\n",
            "Batch [14001/14373], Loss: 0.07345904409885406, Avg. Diff: 1.767524003982544, RMSE: 2.7103327975441696\n",
            "Epoch [2/10], Loss: 0.04020271450281143\n",
            "Batch [1/14373], Loss: 0.060685865581035614, Avg. Diff: 1.7722067832946777, RMSE: 2.4634500907238417\n",
            "Batch [1001/14373], Loss: 0.06419122219085693, Avg. Diff: 1.593658447265625, RMSE: 2.533598575593327\n",
            "Batch [2001/14373], Loss: 0.061253368854522705, Avg. Diff: 1.6633126735687256, RMSE: 2.474941842522941\n",
            "Batch [3001/14373], Loss: 0.08083489537239075, Avg. Diff: 2.0014400482177734, RMSE: 2.843147633232483\n",
            "Batch [4001/14373], Loss: 0.03729259595274925, Avg. Diff: 1.196396827697754, RMSE: 1.931129133275498\n",
            "Batch [5001/14373], Loss: 0.042197056114673615, Avg. Diff: 1.383988857269287, RMSE: 2.0541921968659698\n",
            "Batch [6001/14373], Loss: 0.06542959809303284, Avg. Diff: 1.7931885719299316, RMSE: 2.55792087705168\n",
            "Batch [7001/14373], Loss: 0.04187052696943283, Avg. Diff: 1.3105878829956055, RMSE: 2.0462289037997694\n",
            "Batch [8001/14373], Loss: 0.05377744883298874, Avg. Diff: 1.6046664714813232, RMSE: 2.3189964800927614\n",
            "Batch [9001/14373], Loss: 0.06232883408665657, Avg. Diff: 1.6202611923217773, RMSE: 2.4965742481512505\n",
            "Batch [10001/14373], Loss: 0.05226556211709976, Avg. Diff: 1.4149225950241089, RMSE: 2.28616618474681\n",
            "Batch [11001/14373], Loss: 0.03244834393262863, Avg. Diff: 1.2881553173065186, RMSE: 1.801342394733768\n",
            "Batch [12001/14373], Loss: 0.07914390414953232, Avg. Diff: 1.8726956844329834, RMSE: 2.813252581466457\n",
            "Batch [13001/14373], Loss: 0.04637414962053299, Avg. Diff: 1.410044550895691, RMSE: 2.1534657954680814\n",
            "Batch [14001/14373], Loss: 0.06267207860946655, Avg. Diff: 1.7894587516784668, RMSE: 2.5034390637063484\n",
            "Epoch [3/10], Loss: 0.05247538909316063\n",
            "Batch [1/14373], Loss: 0.03954906761646271, Avg. Diff: 1.3260283470153809, RMSE: 1.9886947831329485\n",
            "Batch [1001/14373], Loss: 0.03234323859214783, Avg. Diff: 1.0140643119812012, RMSE: 1.7984225699221785\n",
            "Batch [2001/14373], Loss: 0.04985754191875458, Avg. Diff: 1.2846194505691528, RMSE: 2.232880205712237\n",
            "Batch [3001/14373], Loss: 0.02724052593111992, Avg. Diff: 1.1171777248382568, RMSE: 1.65047036604697\n",
            "Batch [4001/14373], Loss: 0.07275357842445374, Avg. Diff: 1.6837053298950195, RMSE: 2.697287104339485\n",
            "Batch [5001/14373], Loss: 0.05634162575006485, Avg. Diff: 1.4400804042816162, RMSE: 2.3736391686252634\n",
            "Batch [6001/14373], Loss: 0.07316099852323532, Avg. Diff: 1.6043941974639893, RMSE: 2.704829037211859\n",
            "Batch [7001/14373], Loss: 0.049227356910705566, Avg. Diff: 1.435235619544983, RMSE: 2.2187237805173945\n",
            "Batch [8001/14373], Loss: 0.05457790568470955, Avg. Diff: 1.4916231632232666, RMSE: 2.3361913230552633\n",
            "Batch [9001/14373], Loss: 0.04800922051072121, Avg. Diff: 1.32931387424469, RMSE: 2.1911005089051736\n",
            "Batch [10001/14373], Loss: 0.04967651888728142, Avg. Diff: 1.1735327243804932, RMSE: 2.228822972787354\n",
            "Batch [11001/14373], Loss: 0.04080251231789589, Avg. Diff: 1.3123968839645386, RMSE: 2.0199631721614204\n",
            "Batch [12001/14373], Loss: 0.036446355283260345, Avg. Diff: 1.1595125198364258, RMSE: 1.909092768961343\n",
            "Batch [13001/14373], Loss: 0.0429954007267952, Avg. Diff: 1.3259176015853882, RMSE: 2.0735332268563234\n",
            "Batch [14001/14373], Loss: 0.07634326815605164, Avg. Diff: 1.7889741659164429, RMSE: 2.7630285801660563\n",
            "Epoch [4/10], Loss: 0.050601545721292496\n",
            "Batch [1/14373], Loss: 0.03304146230220795, Avg. Diff: 1.105581283569336, RMSE: 1.8177310829232798\n",
            "Batch [1001/14373], Loss: 0.0518113374710083, Avg. Diff: 1.4930007457733154, RMSE: 2.2762104964036145\n",
            "Batch [2001/14373], Loss: 0.014979812316596508, Avg. Diff: 0.7077022790908813, RMSE: 1.2239204184429058\n",
            "Batch [3001/14373], Loss: 0.03673451393842697, Avg. Diff: 1.2012386322021484, RMSE: 1.9166248842190956\n",
            "Batch [4001/14373], Loss: 0.02677777409553528, Avg. Diff: 0.9702354669570923, RMSE: 1.636391545548998\n",
            "Batch [5001/14373], Loss: 0.03201811760663986, Avg. Diff: 0.9140081405639648, RMSE: 1.789360854412398\n",
            "Batch [6001/14373], Loss: 0.0316806435585022, Avg. Diff: 1.1225106716156006, RMSE: 1.7799056484633224\n",
            "Batch [7001/14373], Loss: 0.06884554773569107, Avg. Diff: 1.4762256145477295, RMSE: 2.623843528676219\n",
            "Batch [8001/14373], Loss: 0.048174332827329636, Avg. Diff: 1.2991657257080078, RMSE: 2.19486522530172\n",
            "Batch [9001/14373], Loss: 0.04048549383878708, Avg. Diff: 1.1189793348312378, RMSE: 2.012100568665814\n",
            "Batch [10001/14373], Loss: 0.029565555974841118, Avg. Diff: 0.995064377784729, RMSE: 1.7194637550511764\n",
            "Batch [11001/14373], Loss: 0.033457156270742416, Avg. Diff: 1.1127030849456787, RMSE: 1.829129717315345\n",
            "Batch [12001/14373], Loss: 0.05015933886170387, Avg. Diff: 1.4610910415649414, RMSE: 2.239628198455198\n",
            "Batch [13001/14373], Loss: 0.03735920041799545, Avg. Diff: 1.2839395999908447, RMSE: 1.9328528015326407\n",
            "Batch [14001/14373], Loss: 0.03559013828635216, Avg. Diff: 1.039036750793457, RMSE: 1.8865348773707782\n",
            "Epoch [5/10], Loss: 0.013946358114480972\n",
            "Batch [1/14373], Loss: 0.047837235033512115, Avg. Diff: 1.3267086744308472, RMSE: 2.1871725654773466\n",
            "Batch [1001/14373], Loss: 0.05637335777282715, Avg. Diff: 1.268838882446289, RMSE: 2.374307431080212\n",
            "Batch [2001/14373], Loss: 0.05413271486759186, Avg. Diff: 1.2240173816680908, RMSE: 2.3266438118359547\n",
            "Batch [3001/14373], Loss: 0.02143688313663006, Avg. Diff: 0.738396406173706, RMSE: 1.4641339426105444\n",
            "Batch [4001/14373], Loss: 0.040227219462394714, Avg. Diff: 1.1403636932373047, RMSE: 2.0056725167042337\n",
            "Batch [5001/14373], Loss: 0.03619377315044403, Avg. Diff: 1.0573334693908691, RMSE: 1.9024661296982524\n",
            "Batch [6001/14373], Loss: 0.033457495272159576, Avg. Diff: 1.112781047821045, RMSE: 1.8291389718127886\n",
            "Batch [7001/14373], Loss: 0.02684687077999115, Avg. Diff: 0.8688548803329468, RMSE: 1.6385014914865839\n",
            "Batch [8001/14373], Loss: 0.032599881291389465, Avg. Diff: 1.1419739723205566, RMSE: 1.8055437046868463\n",
            "Batch [9001/14373], Loss: 0.028712697327136993, Avg. Diff: 0.9994326829910278, RMSE: 1.694482134137559\n",
            "Batch [10001/14373], Loss: 0.042556047439575195, Avg. Diff: 1.1604560613632202, RMSE: 2.0629117150177607\n",
            "Batch [11001/14373], Loss: 0.025616176426410675, Avg. Diff: 0.8705922365188599, RMSE: 1.6005054986651324\n",
            "Batch [12001/14373], Loss: 0.04236456751823425, Avg. Diff: 1.1381243467330933, RMSE: 2.0582655006176234\n",
            "Batch [13001/14373], Loss: 0.046966202557086945, Avg. Diff: 1.3282064199447632, RMSE: 2.167168656908777\n",
            "Batch [14001/14373], Loss: 0.05312824249267578, Avg. Diff: 1.4192376136779785, RMSE: 2.3049564527920214\n",
            "Epoch [6/10], Loss: 0.0505550317466259\n",
            "Batch [1/14373], Loss: 0.03740958869457245, Avg. Diff: 1.0020713806152344, RMSE: 1.934155931532013\n",
            "Batch [1001/14373], Loss: 0.025591876357793808, Avg. Diff: 0.7508300542831421, RMSE: 1.5997460461779436\n",
            "Batch [2001/14373], Loss: 0.021041661500930786, Avg. Diff: 0.8616081476211548, RMSE: 1.4505743796454524\n",
            "Batch [3001/14373], Loss: 0.04178328812122345, Avg. Diff: 1.2457892894744873, RMSE: 2.0440960139140043\n",
            "Batch [4001/14373], Loss: 0.02392096072435379, Avg. Diff: 0.946333646774292, RMSE: 1.5466403205178751\n",
            "Batch [5001/14373], Loss: 0.033416371792554855, Avg. Diff: 1.1430418491363525, RMSE: 1.8280145334630142\n",
            "Batch [6001/14373], Loss: 0.035356294363737106, Avg. Diff: 1.0176995992660522, RMSE: 1.8803269057429715\n",
            "Batch [7001/14373], Loss: 0.056595150381326675, Avg. Diff: 1.4357308149337769, RMSE: 2.3789735981845985\n",
            "Batch [8001/14373], Loss: 0.052454873919487, Avg. Diff: 1.2316677570343018, RMSE: 2.2903028649361565\n",
            "Batch [9001/14373], Loss: 0.04765942692756653, Avg. Diff: 1.2303342819213867, RMSE: 2.183103994404417\n",
            "Batch [10001/14373], Loss: 0.036930255591869354, Avg. Diff: 1.209519386291504, RMSE: 1.9217245771885936\n",
            "Batch [11001/14373], Loss: 0.0323968268930912, Avg. Diff: 1.1127697229385376, RMSE: 1.7999118518438504\n",
            "Batch [12001/14373], Loss: 0.030345411971211433, Avg. Diff: 0.8695201873779297, RMSE: 1.7419935725780036\n",
            "Batch [13001/14373], Loss: 0.01799928769469261, Avg. Diff: 0.7794443368911743, RMSE: 1.3416142457392224\n",
            "Batch [14001/14373], Loss: 0.03895416110754013, Avg. Diff: 1.1175892353057861, RMSE: 1.9736807702687045\n",
            "Epoch [7/10], Loss: 0.016262918710708618\n",
            "Batch [1/14373], Loss: 0.026435015723109245, Avg. Diff: 0.8622317910194397, RMSE: 1.625884768899162\n",
            "Batch [1001/14373], Loss: 0.013647244311869144, Avg. Diff: 0.6364240646362305, RMSE: 1.168214140665149\n",
            "Batch [2001/14373], Loss: 0.021588046103715897, Avg. Diff: 0.8945258855819702, RMSE: 1.4692870436563763\n",
            "Batch [3001/14373], Loss: 0.029240695759654045, Avg. Diff: 0.8195217847824097, RMSE: 1.7099910539538068\n",
            "Batch [4001/14373], Loss: 0.04608569294214249, Avg. Diff: 1.2337745428085327, RMSE: 2.1467578217401786\n",
            "Batch [5001/14373], Loss: 0.025106094777584076, Avg. Diff: 0.9927504062652588, RMSE: 1.5844901861270273\n",
            "Batch [6001/14373], Loss: 0.01725151389837265, Avg. Diff: 0.756904125213623, RMSE: 1.313450151482841\n",
            "Batch [7001/14373], Loss: 0.018521491438150406, Avg. Diff: 0.7831301689147949, RMSE: 1.3609367256731706\n",
            "Batch [8001/14373], Loss: 0.032814763486385345, Avg. Diff: 0.9210413098335266, RMSE: 1.811484545678369\n",
            "Batch [9001/14373], Loss: 0.03544933721423149, Avg. Diff: 1.0612655878067017, RMSE: 1.882799457172472\n",
            "Batch [10001/14373], Loss: 0.03477197512984276, Avg. Diff: 1.009935975074768, RMSE: 1.8647244220681962\n",
            "Batch [11001/14373], Loss: 0.034425538033246994, Avg. Diff: 0.9290321469306946, RMSE: 1.8554119543116663\n",
            "Batch [12001/14373], Loss: 0.018755152821540833, Avg. Diff: 0.8575693368911743, RMSE: 1.3694944264694395\n",
            "Batch [13001/14373], Loss: 0.018967173993587494, Avg. Diff: 0.844433069229126, RMSE: 1.3772136036039515\n",
            "Batch [14001/14373], Loss: 0.022976413369178772, Avg. Diff: 0.6651132106781006, RMSE: 1.5157972414914973\n",
            "Epoch [8/10], Loss: 0.016305552795529366\n",
            "Batch [1/14373], Loss: 0.032413043081760406, Avg. Diff: 1.0865263938903809, RMSE: 1.8003621637731253\n",
            "Batch [1001/14373], Loss: 0.024161234498023987, Avg. Diff: 0.8526970148086548, RMSE: 1.554388429639694\n",
            "Batch [2001/14373], Loss: 0.040747642517089844, Avg. Diff: 1.0692527294158936, RMSE: 2.0186045307858063\n",
            "Batch [3001/14373], Loss: 0.029047340154647827, Avg. Diff: 0.8234485983848572, RMSE: 1.7043279896356491\n",
            "Batch [4001/14373], Loss: 0.02084307000041008, Avg. Diff: 0.8487486839294434, RMSE: 1.443712906133877\n",
            "Batch [5001/14373], Loss: 0.026227101683616638, Avg. Diff: 1.0174881219863892, RMSE: 1.6194783814445652\n",
            "Batch [6001/14373], Loss: 0.021648455411195755, Avg. Diff: 0.7713382840156555, RMSE: 1.471341383436818\n",
            "Batch [7001/14373], Loss: 0.012369154021143913, Avg. Diff: 0.6820161938667297, RMSE: 1.112167014962059\n",
            "Batch [8001/14373], Loss: 0.022166090086102486, Avg. Diff: 0.8144007921218872, RMSE: 1.4888280629944037\n",
            "Batch [9001/14373], Loss: 0.015462798066437244, Avg. Diff: 0.7530619502067566, RMSE: 1.2434949412072345\n",
            "Batch [10001/14373], Loss: 0.007914910092949867, Avg. Diff: 0.4841361939907074, RMSE: 0.889657817167212\n",
            "Batch [11001/14373], Loss: 0.022058971226215363, Avg. Diff: 0.8443368673324585, RMSE: 1.4852262766390898\n",
            "Batch [12001/14373], Loss: 0.03749695047736168, Avg. Diff: 1.0653518438339233, RMSE: 1.9364129370145535\n",
            "Batch [13001/14373], Loss: 0.024566650390625, Avg. Diff: 0.8796707391738892, RMSE: 1.5673752068545999\n",
            "Batch [14001/14373], Loss: 0.04781246930360794, Avg. Diff: 1.1714777946472168, RMSE: 2.186606306351706\n",
            "Epoch [9/10], Loss: 0.008867030963301659\n",
            "Batch [1/14373], Loss: 0.02756599709391594, Avg. Diff: 0.6960204839706421, RMSE: 1.6603010765183857\n",
            "Batch [1001/14373], Loss: 0.019283249974250793, Avg. Diff: 0.783840537071228, RMSE: 1.3886413141635443\n",
            "Batch [2001/14373], Loss: 0.023209940642118454, Avg. Diff: 0.6671743988990784, RMSE: 1.5234808499942072\n",
            "Batch [3001/14373], Loss: 0.02769763208925724, Avg. Diff: 0.98377525806427, RMSE: 1.6642604942913495\n",
            "Batch [4001/14373], Loss: 0.019541854038834572, Avg. Diff: 0.8127256631851196, RMSE: 1.3979218027595657\n",
            "Batch [5001/14373], Loss: 0.03566518798470497, Avg. Diff: 0.9881060123443604, RMSE: 1.8885228473997229\n",
            "Batch [6001/14373], Loss: 0.017885925248265266, Avg. Diff: 0.7218400239944458, RMSE: 1.3373826447812203\n",
            "Batch [7001/14373], Loss: 0.01507172454148531, Avg. Diff: 0.7049764394760132, RMSE: 1.227669574655042\n",
            "Batch [8001/14373], Loss: 0.021065648645162582, Avg. Diff: 0.8701577186584473, RMSE: 1.451400964657296\n",
            "Batch [9001/14373], Loss: 0.008831679821014404, Avg. Diff: 0.5336233973503113, RMSE: 0.9397701434376364\n",
            "Batch [10001/14373], Loss: 0.02293255552649498, Avg. Diff: 0.7565149068832397, RMSE: 1.5143498040849346\n",
            "Batch [11001/14373], Loss: 0.02332344464957714, Avg. Diff: 0.7570251822471619, RMSE: 1.527201536148042\n",
            "Batch [12001/14373], Loss: 0.03279677405953407, Avg. Diff: 0.9895884990692139, RMSE: 1.8109878941157136\n",
            "Batch [13001/14373], Loss: 0.018618334084749222, Avg. Diff: 0.7271876931190491, RMSE: 1.3644901369995739\n",
            "Batch [14001/14373], Loss: 0.02540583908557892, Avg. Diff: 0.7965556383132935, RMSE: 1.593920829443755\n",
            "Epoch [10/10], Loss: 0.00984178390353918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total_loss = 0\n",
        "total_diff = 0\n",
        "total_examples = 0\n",
        "total_squared_error = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        user_ids = batch['user_id'].to(device)\n",
        "        item_ids = batch['book_id'].to(device)\n",
        "        ratings = batch['rating'].to(device)\n",
        "\n",
        "        predictions = model(user_ids, item_ids)\n",
        "        loss = criterion(predictions, (ratings.float() / 10))\n",
        "\n",
        "        actual_ratings = 10 * predictions\n",
        "        diff = torch.abs(actual_ratings - ratings).sum().item()\n",
        "\n",
        "        total_loss += loss.item() * len(ratings)\n",
        "        total_diff += diff\n",
        "        total_examples += len(ratings)\n",
        "        total_squared_error += torch.square(actual_ratings-ratings).sum().item()\n",
        "\n",
        "avg_loss = total_loss / total_examples\n",
        "avg_diff = total_diff / total_examples\n",
        "rmse = math.sqrt(total_squared_error / total_examples)\n",
        "\n",
        "print('Evalution Measures:')\n",
        "print(f'Evaluation Loss: {avg_loss}, Average Difference: {avg_diff}, RMSE: {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OROzsmN18eoZ",
        "outputId": "06db7dbe-f07b-4a9f-bf61-a1e23b22dd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evalution Measures:\n",
            "Evaluation Loss: 0.2532428097037124, Average Difference: 4.3443351952966545, RMSE: 5.032323596139187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/model.pth')\n",
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIwz6O0klyXR",
        "outputId": "3f24265e-59ed-43c1-ffdc-a7a2dfa7e5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('gmf.user_embedding.weight',\n",
              "              tensor([[-0.5624, -1.3819,  1.0367,  ...,  0.4001, -0.1564,  3.3780],\n",
              "                      [ 2.2142,  1.0910,  1.4986,  ..., -0.7640, -0.6616, -0.1932],\n",
              "                      [ 0.3840, -0.5114, -0.2803,  ...,  1.3857,  2.2816, -0.0465],\n",
              "                      ...,\n",
              "                      [-0.3778, -0.4525,  0.4108,  ...,  1.4215,  0.5195, -0.3969],\n",
              "                      [ 0.0695, -0.1079, -1.6765,  ...,  0.6159,  0.6033,  0.3544],\n",
              "                      [ 1.1817, -1.2852,  0.9386,  ..., -0.0533,  0.6412,  0.5811]],\n",
              "                     device='cuda:0')),\n",
              "             ('gmf.item_embedding.weight',\n",
              "              tensor([[ 1.0159, -0.6526,  2.2748,  ..., -0.2538, -1.1148,  0.5335],\n",
              "                      [-1.3188,  1.6271, -1.1525,  ..., -0.3318,  1.5256, -0.2490],\n",
              "                      [ 0.3119, -0.2716,  0.7967,  ...,  0.8804, -0.8818, -0.3855],\n",
              "                      ...,\n",
              "                      [ 1.1299,  1.0908,  0.9183,  ...,  1.0843,  0.9799,  1.9127],\n",
              "                      [ 0.7414, -0.9642, -1.4853,  ..., -0.8033,  1.3365,  0.8746],\n",
              "                      [ 0.1104,  0.6722, -0.0994,  ...,  0.6651, -1.2905, -0.2545]],\n",
              "                     device='cuda:0')),\n",
              "             ('gmf.fc.weight',\n",
              "              tensor([[ 0.3430, -0.5832, -0.4612,  ..., -0.3359,  0.3513, -0.2330],\n",
              "                      [ 0.3107,  0.4682,  0.1171,  ...,  0.0858,  0.2841, -0.1824],\n",
              "                      [ 0.3814,  0.2479,  0.0529,  ..., -0.4101,  0.1703,  0.0264],\n",
              "                      ...,\n",
              "                      [ 0.4178,  0.0239,  0.0428,  ..., -0.1792, -0.1078, -0.1502],\n",
              "                      [-0.2520, -0.1574,  0.2903,  ..., -0.0792,  0.3242, -0.7720],\n",
              "                      [-0.1347,  0.2453,  0.2063,  ...,  0.1762,  0.5624, -0.1269]],\n",
              "                     device='cuda:0')),\n",
              "             ('gmf.fc.bias',\n",
              "              tensor([-2.8338, -2.8360, -2.9147, -2.7253, -2.7450, -2.9828, -2.6944, -3.1842,\n",
              "                      -2.7597, -2.9548, -3.0240, -2.8413, -2.7936, -3.0355, -2.8361, -2.9574,\n",
              "                      -3.0407, -2.9025, -2.7686, -2.9022, -2.7927, -2.8548, -2.8149, -2.8545,\n",
              "                      -3.0356, -2.7207, -3.0793, -3.0014, -2.7637, -2.9002, -2.8809, -3.0023],\n",
              "                     device='cuda:0')),\n",
              "             ('gmf.output_layer.weight',\n",
              "              tensor([[-0.6786, -0.5709, -0.6608, -0.5858, -0.5577, -0.8805, -0.4691, -1.0185,\n",
              "                       -0.5689, -0.8250, -0.7951, -0.5957, -0.6340, -0.9258, -0.6568, -0.8160,\n",
              "                       -0.8934, -0.6194, -0.4955, -0.6645, -0.5685, -0.7532, -0.5519, -0.6548,\n",
              "                       -0.8109, -0.5548, -0.9853, -0.8604, -0.6153, -0.6501, -0.6644, -0.8692]],\n",
              "                     device='cuda:0')),\n",
              "             ('gmf.output_layer.bias', tensor([5.5705], device='cuda:0')),\n",
              "             ('mlp.user_embedding.weight',\n",
              "              tensor([[ 1.2301,  1.5684,  0.2295,  ..., -0.0225,  0.8171, -0.6747],\n",
              "                      [ 0.4239, -0.1884,  1.2750,  ..., -1.2648,  0.6596,  1.1592],\n",
              "                      [-2.2920,  1.7841, -2.4299,  ..., -0.0266, -2.6770, -0.2143],\n",
              "                      ...,\n",
              "                      [ 0.0657,  1.5027, -0.4112,  ...,  0.5451, -0.0493, -2.0766],\n",
              "                      [-0.8619,  1.6342,  0.1271,  ..., -0.8080, -1.3655, -0.8739],\n",
              "                      [ 1.0726,  0.3072,  1.0299,  ..., -0.5464,  0.1376,  0.9406]],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.item_embedding.weight',\n",
              "              tensor([[-1.3379,  0.8391, -1.3337,  ...,  0.3117, -1.4499,  0.4264],\n",
              "                      [ 1.0880,  0.3136, -1.7810,  ..., -0.5696,  0.9249, -0.6404],\n",
              "                      [ 0.3390, -0.5412,  0.0176,  ...,  2.3952,  2.0472, -0.3056],\n",
              "                      ...,\n",
              "                      [-1.7422,  1.0956,  1.8368,  ..., -0.4924,  1.8291, -1.3105],\n",
              "                      [ 1.4396,  0.2917,  1.1979,  ...,  0.1291,  0.0392, -1.2442],\n",
              "                      [ 1.2395,  1.7192, -0.2341,  ..., -1.1204,  1.4668, -0.7353]],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.0.weight',\n",
              "              tensor([[-0.3722, -0.1230, -0.0609,  ..., -0.3568, -0.4272, -0.1729],\n",
              "                      [ 0.3564,  0.0297, -0.1804,  ...,  0.2221,  0.0704, -0.2783],\n",
              "                      [ 0.1370, -0.2469, -0.2662,  ...,  0.2652,  0.3359,  0.4415],\n",
              "                      ...,\n",
              "                      [-0.1848,  0.0382, -0.6003,  ..., -0.6083,  0.1453, -0.1252],\n",
              "                      [ 0.4060, -0.0302, -0.0196,  ...,  0.1621,  0.4817, -0.3720],\n",
              "                      [ 0.3121, -0.2553,  0.1280,  ...,  0.0421,  0.1022, -0.3226]],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.0.bias',\n",
              "              tensor([-1.7876, -3.1112, -2.7475, -3.3911, -1.4653, -1.7773, -1.8500, -2.9565,\n",
              "                      -2.1668, -2.9145, -2.8561, -2.5843, -3.2415, -2.7613, -2.1573, -3.4815,\n",
              "                      -1.9802, -2.9134, -2.4861, -3.3149, -1.7759, -1.8344, -2.0760, -3.5817,\n",
              "                      -2.9862, -2.1439, -2.4197, -3.3108, -2.8961, -3.0889, -3.0969, -2.9992,\n",
              "                      -2.7405, -2.9516, -1.6553, -3.2757, -3.5835, -1.3897, -3.0910, -1.7269,\n",
              "                      -2.7413, -3.2372, -2.6643, -2.9842, -2.7968, -2.4658, -1.7668, -1.3587,\n",
              "                      -1.5717, -3.0623, -3.3348, -1.8423, -2.9170, -2.9664, -1.0429, -3.1089,\n",
              "                      -2.1032, -3.0654, -3.1228, -1.8194, -2.9499, -1.3713, -2.7567, -2.6979,\n",
              "                      -1.3475, -2.0359, -2.3207, -1.1550, -3.2449, -2.3870, -2.1408, -1.8727,\n",
              "                      -1.9836, -3.1205, -2.2572, -1.4494, -1.7575, -2.4606, -3.1973, -2.5421,\n",
              "                      -2.3796, -2.6949, -2.0038, -2.7567, -2.6737, -1.3441, -3.2204, -3.0983,\n",
              "                      -2.7501, -1.9556, -2.6427, -3.4258, -3.3158, -2.7382, -2.1237, -2.4471,\n",
              "                      -2.6722, -2.0991, -2.9196, -3.5116, -2.9651, -3.2837, -1.6527, -3.0591,\n",
              "                      -2.7933, -1.8664, -3.1671, -3.1974, -3.4121, -3.5179, -3.2976, -2.9611,\n",
              "                      -3.0684, -2.8612, -3.3085, -3.2790, -1.5079, -2.8206, -2.4454, -3.2815,\n",
              "                      -2.3382, -1.2838, -2.0547, -2.8423, -1.6997, -3.4559, -2.4866, -3.3299],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.3.weight',\n",
              "              tensor([[ 0.0858, -0.0639,  0.3331,  ..., -0.3106, -0.9271, -0.4609],\n",
              "                      [-0.5606,  0.0677,  0.2528,  ...,  0.1440, -0.2534,  0.1870],\n",
              "                      [-0.1834,  0.5573, -0.3011,  ..., -0.3866,  0.2046,  0.2216],\n",
              "                      ...,\n",
              "                      [ 0.0225, -0.2180, -0.1266,  ...,  0.0036, -0.5164,  0.1598],\n",
              "                      [-0.3303,  0.0558,  0.2553,  ...,  0.2448,  0.5370,  0.0793],\n",
              "                      [-0.1716, -0.4586,  0.0418,  ..., -0.0099, -0.1176, -0.0220]],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.3.bias',\n",
              "              tensor([ 1.5707, -0.5021, -0.5668, -0.9599, -0.8563,  2.0837, -0.9096, -0.8627,\n",
              "                      -0.7714, -0.5007, -0.2301, -0.5235, -0.3534,  1.6022, -0.6507, -0.3783,\n",
              "                      -0.3044, -0.7112, -0.9918, -1.0933, -0.6383, -0.2269, -1.0328, -0.3186,\n",
              "                      -0.6150, -0.7399, -0.6022, -1.2417, -0.9754, -0.6299, -0.8788, -0.6558,\n",
              "                      -0.5157,  1.3462, -0.3608,  0.9806, -0.9940, -0.5482, -1.0820, -0.7739,\n",
              "                      -0.6327, -0.9947, -0.9662,  1.7809,  1.6430, -0.2440, -0.5697, -1.5239,\n",
              "                       1.6836, -0.8346,  1.5596,  1.9132, -0.8600, -1.1844,  1.7087,  2.4257,\n",
              "                      -0.6916, -0.5726, -0.4166, -0.7167, -0.7847,  1.3921, -0.7300, -0.6137],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.6.weight',\n",
              "              tensor([[ 0.0670,  0.1605, -0.1014,  ...,  0.0657,  0.1006,  0.0635],\n",
              "                      [ 0.1229,  0.3301, -0.0806,  ..., -0.0168, -0.1966,  0.1391],\n",
              "                      [ 0.2920, -0.3710, -0.1117,  ...,  0.1657, -0.8792, -0.0972],\n",
              "                      ...,\n",
              "                      [-0.3410,  0.1009, -0.0302,  ...,  0.1489,  0.1209,  0.0331],\n",
              "                      [-0.3611,  0.0049,  0.1491,  ..., -0.1031,  0.1192,  0.1105],\n",
              "                      [-0.1281, -0.0181,  0.0074,  ..., -0.1969, -0.0682,  0.2361]],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.6.bias',\n",
              "              tensor([-0.5787, -1.0806,  0.0837, -0.5514, -0.4944, -0.5702,  1.5157,  0.6926,\n",
              "                      -0.2450,  1.3152,  0.2567,  1.3927,  0.8900,  1.5771, -0.6455,  1.4643,\n",
              "                       1.2852,  1.5100,  1.2705, -0.8285,  1.6080, -0.3710,  1.1477, -0.6711,\n",
              "                      -0.5777, -0.3901,  1.2912, -0.4805, -0.3958, -0.5223, -0.5450, -0.4987],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.9.weight',\n",
              "              tensor([[-0.0253, -0.0166,  0.0460, -0.0262,  0.0035, -0.0275,  0.0387,  0.0340,\n",
              "                       -0.0280,  0.0239,  0.0093,  0.0351,  0.0164,  0.0201, -0.0143,  0.0112,\n",
              "                        0.0101,  0.0496,  0.0347, -0.0232,  0.0198, -0.0285,  0.0398,  0.0027,\n",
              "                       -0.0182, -0.0154,  0.0220, -0.0126, -0.0179, -0.0331, -0.0217, -0.0141]],\n",
              "                     device='cuda:0')),\n",
              "             ('mlp.layers.9.bias', tensor([-0.0562], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for i in range(0,100):\n",
        "    print(i)\n",
        "    time.sleep(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xLLUSajP6jt",
        "outputId": "dc12f051-2a12-4223-c19a-ebfa65438374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ณ mlp & GMF =3 คือด้านบน\n",
        "\n",
        "ณ mlp & GMF =5 คือด้านล่าง\n"
      ],
      "metadata": {
        "id": "PLdI1nYZPjcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ouuRVei-Pip_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# b=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpvPKELcjcPA",
        "outputId": "9cae9540-a979-48be-8bc9-72d482654c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evalution Measures:\n",
            "Evaluation Loss: 0.2668351027242426, Average Difference: 4.466952350663153, RMSE: 5.1656083992964135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Measure¶\n",
        "The average distance is the 'mean' of all differences between ground-truth and predicted\n",
        "The RMSE is the root mean squared of error (highest RMSE=10 and lowest RMSE=0)"
      ],
      "metadata": {
        "id": "-6A9MUZzjy2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ze3SGG10jeDM",
        "outputId": "c75eafaa-9257-4794-8f32-dcd79f6d213f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   User-ID                            Location   Age\n",
              "0        1                  nyc, new york, usa   NaN\n",
              "1        2           stockton, california, usa  18.0\n",
              "2        3     moscow, yukon territory, russia   NaN\n",
              "3        4           porto, v.n.gaia, portugal  17.0\n",
              "4        5  farnborough, hants, united kingdom   NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89d881aa-846f-4235-9e73-c875a18f723b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User-ID</th>\n",
              "      <th>Location</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>nyc, new york, usa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>stockton, california, usa</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>moscow, yukon territory, russia</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>porto, v.n.gaia, portugal</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>farnborough, hants, united kingdom</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89d881aa-846f-4235-9e73-c875a18f723b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89d881aa-846f-4235-9e73-c875a18f723b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89d881aa-846f-4235-9e73-c875a18f723b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6aa392fc-3087-434d-b557-1bd04c91f926\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6aa392fc-3087-434d-b557-1bd04c91f926')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6aa392fc-3087-434d-b557-1bd04c91f926 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "users"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users[users['User-ID'] == 276704]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "3FdRElY-jgRx",
        "outputId": "15f46e89-85a3-4ccb-d599-1abe045a96c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        User-ID                Location  Age\n",
              "276703   276704  cedar park, texas, usa  NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d64f867-1782-4e2d-8f21-ee8b950def46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User-ID</th>\n",
              "      <th>Location</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>276703</th>\n",
              "      <td>276704</td>\n",
              "      <td>cedar park, texas, usa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d64f867-1782-4e2d-8f21-ee8b950def46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d64f867-1782-4e2d-8f21-ee8b950def46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d64f867-1782-4e2d-8f21-ee8b950def46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"users[users['User-ID'] == 276704]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"User-ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 276704,\n        \"max\": 276704,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          276704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"cedar park, texas, usa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have chosen a random user from the dataset. This user is from Texas, USA¶\n",
        "Next, we will choose the top 64 rated books in our database and then recommend 3 books to this user¶"
      ],
      "metadata": {
        "id": "uNyJCFhcjnz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratings = ratings_df.groupby('item_id')['Book-Rating'].mean().reset_index()\n",
        "book_ratings = book_ratings.sort_values(by='Book-Rating', ascending=False)\n",
        "top_64_books = book_ratings.head(64)\n",
        "print(top_64_books)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLmI2pTSjq_r",
        "outputId": "0ad8b9b3-5a6f-42b0-8c80-0d8bf55b9102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        item_id  Book-Rating\n",
            "179431   179431         10.0\n",
            "179429   179429         10.0\n",
            "68077     68077         10.0\n",
            "340350   340350         10.0\n",
            "340429   340429         10.0\n",
            "...         ...          ...\n",
            "251580   251580         10.0\n",
            "251274   251274         10.0\n",
            "251590   251590         10.0\n",
            "251593   251593         10.0\n",
            "251637   251637         10.0\n",
            "\n",
            "[64 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 276704\n",
        "user_id_tensor = torch.LongTensor([user_id] * 64).to(device)\n",
        "\n",
        "top_64_books = top_64_books['item_id'].tolist()\n",
        "item_ids_tensor = torch.LongTensor(top_64_books).to(device)\n",
        "\n",
        "print(\"User ID Tensor:\", user_id_tensor)\n",
        "print(\"Top 10 Books Tensor:\", item_ids_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n33EdE7_jtCo",
        "outputId": "7a8e7e27-1b7d-4068-db16-06b3a644cfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID Tensor: tensor([276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704, 276704,\n",
            "        276704], device='cuda:0')\n",
            "Top 10 Books Tensor: tensor([179431, 179429,  68077, 340350, 340429,  68362,  68395,  68354,  68338,\n",
            "        340469,     67,     52,     53,     54, 340461, 179453, 251314,  30015,\n",
            "        251390,  30007, 251318, 148441, 148430, 148435,  29980, 251312, 251313,\n",
            "        148426,  56646,  56649, 148445, 179544, 179476, 179504, 179405, 179409,\n",
            "        179505, 179517, 340309,    132, 179538,  69093,  69071,    148,    145,\n",
            "        340319, 251149, 251152, 251201, 251173, 251311,  30082,  30072, 251050,\n",
            "        251264, 251266, 251601, 251797, 251594, 251580, 251274, 251590, 251593,\n",
            "        251637], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(user_id_tensor, item_ids_tensor)\n",
        "\n",
        "indexed_predictions = [(idx, pred) for idx, pred in enumerate(predictions)]\n",
        "\n",
        "# Sort the indexed predictions by the prediction values in descending order\n",
        "sorted_predictions = sorted(indexed_predictions, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get the top 3 indices\n",
        "top_3_indices = [idx for idx, _ in sorted_predictions[:3]]\n",
        "\n",
        "# Get the top 3 book ISBNs\n",
        "top_3_book_isbns = [item_ids_tensor[idx].item() for idx in top_3_indices]\n",
        "\n",
        "print(\"Top 3 Book ISBNs:\", top_3_book_isbns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "vb8S37dwjubK",
        "outputId": "a9437cba-0e00-46b7-fd48-f7cbaab698ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e9ee6f268176>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Sort the indexed predictions by the prediction values in descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msorted_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get the top 3 indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ea6TuHgpkCei"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}